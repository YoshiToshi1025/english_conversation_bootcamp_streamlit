import streamlit as st
import os
import time
from time import sleep
from pathlib import Path
from streamlit.components.v1 import html
from langchain_classic.memory import ConversationSummaryBufferMemory
from langchain_classic.chains import ConversationChain
from langchain_core.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain_core.messages import SystemMessage
from openai import OpenAI
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import functions as ft
import constants as ct


# å„ç¨®è¨­å®š
load_dotenv()   # .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
app_title = ct.APP_NAME + " (ver." + ct.APP_VERSION + ")"    # ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¨­å®š
st.set_page_config(page_title=app_title)    # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«è¨­å®š
st.markdown(f"## {app_title}")  # ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º

# åˆæœŸè¨­å®š
if "messages" not in st.session_state:
    st.session_state.messages = []                                                  # ãƒ¦ãƒ¼ã‚¶ã¨AIã®ä¼šè©±å±¥æ­´
    st.session_state.qa_messages = []                                               # ãƒ¦ãƒ¼ã‚¶ã¨AIã®Q&Aå±¥æ­´
    st.session_state.user_input_mode = ""                                           # ãƒ¦ãƒ¼ã‚¶ã®å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ï¼ˆéŸ³å£° or ãƒ†ã‚­ã‚¹ãƒˆï¼‰
    st.session_state.pre_situation = ""                                             # å‰å›ã®ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
    st.session_state.openai_obj = OpenAI(api_key=os.environ["OPENAI_API_KEY"])      # OpenAIã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    st.session_state.llm = ChatOpenAI(model_name="gpt-5-nano", temperature=0.5)    # LLMã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    st.session_state.conversation_memory = ConversationSummaryBufferMemory(
        llm=st.session_state.llm,
        max_token_limit=1000,
        return_messages=True
    )                                                                               # è‹±ä¼šè©±ç”¨ã®ãƒ¡ãƒ¢ãƒª
    st.session_state.evaluation_memory = ConversationSummaryBufferMemory(
        llm=st.session_state.llm,
        max_token_limit=1000,
        return_messages=True
    )                                                                               # è‹±ä¼šè©±è©•ä¾¡ç”¨ã®ãƒ¡ãƒ¢ãƒª
    st.session_state.qa_memory = ConversationSummaryBufferMemory(
        llm=st.session_state.llm,
        max_token_limit=1000,
        return_messages=True
    )                                                                               # è³ªå•å›ç­”ç”¨ã®ãƒ¡ãƒ¢ãƒª
    st.session_state.user_input_update_flag = False                                 # ãƒ¦ãƒ¼ã‚¶å…¥åŠ›å€¤æ›´æ–°ãƒ•ãƒ©ã‚°
    st.session_state.llm_response_evaluation = ""                                   # è‹±ä¼šè©±è©•ä¾¡ç”¨ã®LLMå›ç­”

# å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ç”»é¢è¨­å®š
with st.sidebar:
    st.markdown("## âš™ï¸ AIä¼šè©±è¨­å®š")
    st.session_state.ai_conversation_setting_situation = st.selectbox("ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³", options=ct.SITUATION_OPTION, label_visibility="visible")
    st.session_state.ai_conversation_setting_conversation_level = st.selectbox("ä¼šè©±ãƒ¬ãƒ™ãƒ«", options=ct.CONVERSATION_LEVEL_OPTION, label_visibility="visible")
    st.session_state.ai_conversation_setting_language = st.selectbox("è¨€èª", options=ct.LANGUAGE_OPTION, label_visibility="visible")
    st.session_state.ai_conversation_setting_speed_key = st.selectbox("ç™ºå£°é€Ÿåº¦", options=list(ct.PLAY_SPEED_OPTION.keys()), index=1, label_visibility="visible")
    st.session_state.ai_conversation_setting_speed_value = ct.PLAY_SPEED_OPTION[st.session_state.ai_conversation_setting_speed_key]

    # ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã«ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ
    if st.session_state.pre_situation == "":
        st.session_state.pre_situation = st.session_state.ai_conversation_setting_situation
    elif st.session_state.pre_situation != st.session_state.ai_conversation_setting_situation:
        st.session_state.messages = []
        st.session_state.pre_situation = st.session_state.ai_conversation_setting_situation
        st.session_state.conversation_memory.clear()
        st.session_state.evaluation_memory.clear()
        st.session_state.qa_memory.clear()
        st.rerun()

# è‹±ä¼šè©±ç”¨ã®Chainä½œæˆ
if "chain_basic_conversation" not in st.session_state or st.session_state.messages == []:
    st.session_state.chain_basic_conversation = ft.create_chain_with_memory(
        ct.SYSTEM_TEMPLATE_BASIC_CONVERSATION.format(
            situation=st.session_state.ai_conversation_setting_situation,
            conversation_level=st.session_state.ai_conversation_setting_conversation_level,
            language=st.session_state.ai_conversation_setting_language
        ), st.session_state.conversation_memory)

# è‹±ä¼šè©±å†…å®¹ã®ç·åˆè©•ä¾¡ç”¨ã®Chainä½œæˆ
if "chain_overall_evaluation" not in st.session_state or st.session_state.messages == []:
    st.session_state.chain_overall_evaluation = ft.create_chain_with_memory(
        ct.SYSTEM_TEMPLATE_OVERALL_EVALUATION.format(
            situation=st.session_state.ai_conversation_setting_situation,
            conversation_level=st.session_state.ai_conversation_setting_conversation_level,
            language=st.session_state.ai_conversation_setting_language
        ), st.session_state.evaluation_memory)

# è³ªå•å›ç­”ç”¨ã®Chainä½œæˆ
if "chain_qa_tutor" not in st.session_state or st.session_state.messages == []:
    st.session_state.chain_qa_tutor = ft.create_chain_with_memory(
        ct.SYSTEM_TEMPLATE_QA_TUTOR.format(
            situation=st.session_state.ai_conversation_setting_situation,
            conversation_level=st.session_state.ai_conversation_setting_conversation_level,
            language=st.session_state.ai_conversation_setting_language
        ), st.session_state.qa_memory)

# ã‚¿ãƒ–å®šç¾©ã€€    ãƒ‡ãƒãƒƒã‚°ã‚¿ãƒ–è¡¨ç¤ºæŒ‡å®šãŒã‚ã‚‹å ´åˆã¯ãƒ‡ãƒãƒƒã‚°ã‚¿ãƒ–ã‚’è¡¨ç¤º
if ct.DEBUG_TAB_FLAG:
    conversation_tab, review_tab, qa_tab, debug_tab = st.tabs(["ğŸ—£ï¸ AIã¨è‹±ä¼šè©±", "ğŸ“œ AIã«ã‚ˆã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹", "ğŸ™‹ AIã«ä½•ã§ã‚‚ç›¸è«‡", "ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°"])
else:
    conversation_tab, review_tab, qa_tab = st.tabs(["ğŸ—£ï¸ AIã¨è‹±ä¼šè©±", "ğŸ“œ AIã«ã‚ˆã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹", "ğŸ™‹ AIã«ä½•ã§ã‚‚ç›¸è«‡"])

# è‹±ä¼šè©±ã‚¿ãƒ–å†…ã®ç”»é¢è¨­å®šãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼
with conversation_tab:
    st.info("AIã¨è‹±ä¼šè©±ï¼šç”ŸæˆAIç›¸æ‰‹ã«éŸ³å£°ã‚„ãƒ†ã‚­ã‚¹ãƒˆã§è‹±ä¼šè©±ã®çŒ›ç‰¹è¨“ã‚’è¡Œã†ãŸã‚ã®ã‚¢ãƒ—ãƒªã§ã™ã€‚è‹±èªã‚’ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹ã¾ã§ã€ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã¾ã—ã‚‡ã†ï¼",icon="ğŸ—£ï¸")

    # æ“ä½œèª¬æ˜ã®è¡¨ç¤º
    with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
        st.success("""
            ã€æ“ä½œèª¬æ˜ã€‘
            - ç”»é¢å·¦å´ã®"AIä¼šè©±è¨­å®š"æ¬„ã§ã€AIã¨ã®ä¼šè©±æ¡ä»¶ã‚’è¨­å®šã—ã¾ã™ã€‚ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¤‰æ›´ã™ã‚‹ã¨ã€ä¼šè©±å±¥æ­´ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™ã€‚
            - ã€ŒéŸ³å£°ã§ä¼šè©±ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ä¸‹ã™ã‚‹ã¨ã€éŸ³å£°ã§AIã¨ä¼šè©±ã§ãã¾ã™ã€‚
            - ã€Œãƒ†ã‚­ã‚¹ãƒˆã§ä¼šè©±ã€æ¬„ã«ä¼šè©±æ–‡ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãƒ†ã‚­ã‚¹ãƒˆã§AIã¨ä¼šè©±ã§ãã¾ã™ã€‚
        """)
    st.divider()

    # ãƒ¦ãƒ¼ã‚¶ã¨AIã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            with st.chat_message(message["role"], avatar=ct.AI_ICON_PATH):
                st.markdown(message["content"])
        elif message["role"] == "user":
            with st.chat_message(message["role"], avatar=ct.USER_ICON_PATH):
                st.markdown(message["content"])
        else:
            st.divider()

    # éŸ³å£°å…¥åŠ›ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãŒã‚ã£ãŸå ´åˆã®å‡¦ç†
    if st.session_state.messages == []:
        # æœ€åˆã®ä¼šè©±æ–‡ã‚’ç”Ÿæˆã—ã¦éŸ³å£°èª­ã¿ä¸Šã’
        with st.spinner("æœ€åˆã®ä¼šè©±æ–‡ã®ç”Ÿæˆä¸­..."):
            llm_response = st.session_state.chain_basic_conversation.predict(input="")

            # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            llm_response_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=llm_response
            )

            # ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
            ft.save_to_wav(llm_response_audio.content, audio_output_file_path)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        ft.play_wav(audio_output_file_path, speed=st.session_state.ai_conversation_setting_speed_value)

        # LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§ã«è¿½åŠ 
        st.session_state.messages.append({"role": "assistant", "content": llm_response})

    # éŸ³å£°å…¥åŠ›ã¨ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®ãƒœã‚¿ãƒ³ãƒ»ãƒãƒ£ãƒƒãƒˆæ¬„ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
    col1, col2 = st.columns([1, 5])

    with col1:
        user_input_voice_flag = st.button("éŸ³å£°ã§ä¼šè©±", use_container_width=False, type="primary")
    with col2:
        user_input_text = st.chat_input("ãƒ†ã‚­ã‚¹ãƒˆã§ä¼šè©±")

    # ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ãŒã‚ã£ãŸå ´åˆã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š
    if user_input_voice_flag:
        st.session_state.user_input_mode = "voice"
    elif user_input_text and len(user_input_text.strip()) > 0:
        st.session_state.user_input_mode = "text"
        st.session_state.user_input_text = user_input_text.strip()

    # ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸå‡¦ç†
    if st.session_state.user_input_mode == "voice":
        # éŸ³å£°å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰é¸æŠæ™‚ã®å‡¦ç†

        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        ft.record_audio_on_streamlit(audio_input_file_path)

        # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            transcript = ft.transcribe_audio(audio_input_file_path)
            user_input_text = transcript.text

        # éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(user_input_text)

        with st.spinner("AIä¼šè©±æ–‡ã®ç”Ÿæˆä¸­..."):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’LLMã«æ¸¡ã—ã¦å›ç­”å–å¾—
            llm_response = st.session_state.chain_basic_conversation.predict(input=user_input_text)
            
            # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            llm_response_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=llm_response
            )

            # ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
            ft.save_to_wav(llm_response_audio.content, audio_output_file_path)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        ft.play_wav(audio_output_file_path, speed=st.session_state.ai_conversation_setting_speed_value)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã¨LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": user_input_text})
        st.session_state.messages.append({"role": "assistant", "content": llm_response})

        # å‡¦ç†ç”¨ãƒ•ãƒ©ã‚°ã®ãƒªã‚»ãƒƒãƒˆ
        st.session_state.user_input_update_flag = True
        st.session_state.user_input_mode = ""

        st.rerun()

    elif st.session_state.user_input_mode == "text":
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ¢ãƒ¼ãƒ‰é¸æŠæ™‚ã®å‡¦ç†

        user_input_text = st.session_state.user_input_text 

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(user_input_text)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
        user_input_audio = st.session_state.openai_obj.audio.speech.create(
            model="tts-1",
            voice="echo",
            input=user_input_text
        )

        # ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
        audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
        ft.save_to_wav(user_input_audio.content, audio_output_file_path)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        ft.play_wav(audio_output_file_path, speed=st.session_state.ai_conversation_setting_speed_value)

        #ã€€LLMä¼šè©±æ–‡ã®ç”Ÿæˆã¨èª­ã¿ä¸Šã’
        with st.spinner("AIä¼šè©±æ–‡ã®ç”Ÿæˆä¸­..."):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’LLMã«æ¸¡ã—ã¦å›ç­”å–å¾—
            llm_response = st.session_state.chain_basic_conversation.predict(input=user_input_text)
            
            # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            llm_response_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=llm_response
            )

            # ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
            ft.save_to_wav(llm_response_audio.content, audio_output_file_path)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        ft.play_wav(audio_output_file_path, speed=st.session_state.ai_conversation_setting_speed_value)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã¨LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": user_input_text})
        st.session_state.messages.append({"role": "assistant", "content": llm_response})

        # å‡¦ç†ç”¨ãƒ•ãƒ©ã‚°ã®ãƒªã‚»ãƒƒãƒˆ
        st.session_state.user_input_update_flag = True
        st.session_state.user_input_mode = ""

        st.rerun()

# è©•ä¾¡ã‚¿ãƒ–å†…ã®ç”»é¢è¨­å®šãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼
with review_tab:
    st.info("AIã«ã‚ˆã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼šã‚ãªãŸã®ä¼šè©±å†…å®¹ã«ã¤ã„ã¦ã€AIã«ã‚ˆã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã„ã¾ã™ã€‚",icon="ğŸ“œ")

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€å¾Œã®ä¼šè©±æ–‡ã‚’å–å¾—
    user_input_text = ""
    for message in st.session_state.messages:
        if message["role"] == "user":
            user_input_text = message["content"]

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€å¾Œã®ä¼šè©±æ–‡ãŒå­˜åœ¨ã™ã‚‹å ´åˆã«ã€è©•ä¾¡ã‚’å®Ÿè¡Œã—ç”»é¢ã«è¡¨ç¤ºã™ã‚‹
    if user_input_text and len(user_input_text.strip()) > 0:
        user_input_text = user_input_text.strip()

        # ãƒ¦ãƒ¼ã‚¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(user_input_text)

        if st.session_state.user_input_update_flag == True:
            with st.spinner("ä¼šè©±å†…å®¹ã®åˆ†æä¸­..."):
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’è‹±ä¼šè©±è©•ä¾¡ç”¨LLMã«æ¸¡ã—ã¦è©•ä¾¡çµæœã‚’å–å¾—
                llm_response_evaluation = st.session_state.chain_overall_evaluation.predict(input=user_input_text)
                st.session_state.llm_response_evaluation = llm_response_evaluation
                st.session_state.user_input_update_flag = False

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(st.session_state.llm_response_evaluation)

# è³ªå•ãƒ»ç›¸è«‡ã‚¿ãƒ–å†…ã®ç”»é¢è¨­å®šãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼
with qa_tab:
    st.info("AIã«ä½•ã§ã‚‚ç›¸è«‡ï¼šãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ã€AIã«è‹±ä¼šè©±ã«é–¢é€£ã™ã‚‹è³ªå•ã‚„ç›¸è«‡ãŒã§ãã¾ã™ã€‚",icon="ğŸ™‹")

    # ãƒ¦ãƒ¼ã‚¶ã¨AIã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®è¡¨ç¤º
    for qa_message in st.session_state.qa_messages:
        if qa_message["role"] == "user":
            with st.chat_message(qa_message["role"], avatar=ct.USER_ICON_PATH):
                st.markdown(qa_message["content"])
        elif qa_message["role"] == "assistant":
            with st.chat_message(qa_message["role"], avatar=ct.AI_ICON_PATH):
                st.markdown(qa_message["content"])

    # ãƒ¦ãƒ¼ã‚¶ã®è³ªå•å…¥åŠ›æ¬„
    question_text = st.chat_input("è‹±ä¼šè©±ã«é–¢ã—ã¦çŸ¥ã‚ŠãŸã„ã“ã¨ãŒã‚ã‚Œã°ã€AIã«è³ªå•ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")

    # ãƒ¦ãƒ¼ã‚¶ã®è³ªå•å…¥åŠ›ãŒã‚ã£ãŸå ´åˆã®å‡¦ç†
    if question_text and len(question_text.strip()) > 0:
        question_text = question_text.strip()

        # ãƒ¦ãƒ¼ã‚¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(question_text)

        with st.spinner("å›ç­”ã®ç”Ÿæˆä¸­..."):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’LLMã«æ¸¡ã—ã¦å›ç­”å–å¾—
            llm_response_qa = st.session_state.chain_qa_tutor.predict(input=question_text)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response_qa)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã¨LLMã‹ã‚‰ã®å›ç­”ã‚’Q&Aä¸€è¦§ã«è¿½åŠ 
        st.session_state.qa_messages.append({"role": "user", "content": question_text})
        st.session_state.qa_messages.append({"role": "assistant", "content": llm_response_qa})

        st.rerun()

# ãƒ‡ãƒãƒƒã‚°ã‚¿ãƒ–å†…ã®ç”»é¢è¨­å®šãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼
if ct.DEBUG_TAB_FLAG:
    with debug_tab:
        st.info("ãƒ‡ãƒãƒƒã‚°ï¼šã‚¢ãƒ—ãƒªã®å‹•ä½œç¢ºèªã‚„å•é¡Œè§£æ±ºã®ãŸã‚ã®æƒ…å ±ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚",icon="ğŸ› ï¸")

        st.info(f"""
            ç¾åœ¨ã®AIä¼šè©±è¨­å®š
            - ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼š{st.session_state.ai_conversation_setting_situation}
            - ä¼šè©±ãƒ¬ãƒ™ãƒ«ï¼š{st.session_state.ai_conversation_setting_conversation_level}
            - è¨€èªï¼š{st.session_state.ai_conversation_setting_language}
            - ç™ºå£°é€Ÿåº¦ï¼š{st.session_state.ai_conversation_setting_speed_key}ï¼ˆ{st.session_state.ai_conversation_setting_speed_value}å€é€Ÿï¼‰
        """,icon="âš™ï¸")

        st.info(f"{st.session_state}", icon="ğŸ› ï¸",)
